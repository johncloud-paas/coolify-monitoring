# documentation: https://docs.example.com/
# slogan: A brief description of your service.
# tags: tag1,tag2,tag3
# logo: svgs/your-service.svg
# port: 1234

services:
  # https://coolify.io/docs/get-started/contribute/service
  node_exporter:
    image: quay.io/prometheus/node-exporter:latest
    command:
      - '--path.rootfs=/host'
    pid: host
    volumes:
      - /:/host:ro,rslave
    environment:
      - TZ=${TZ}
    depends_on:
      - prometheus

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    command: -max_procs=1 -docker_only=true
    environment:
      - TZ=${TZ}
    depends_on:
      - prometheus

  pdc:
    # https://grafana.com/docs/grafana-cloud/connect-externally-hosted/private-data-source-connect/#private-data-source-connect-pdc-concepts
    image: grafana/pdc-agent:latest
    depends_on:
      - prometheus
    environment:
      - GRAFANA_PDC_TOKEN=${GRAFANA_PDC_TOKEN}
      - GRAFANA_PDC_CLUSTER=${GRAFANA_PDC_CLUSTER}
      - GRAFANA_PDC_GCP_ID=${GRAFANA_PDC_GCP_ID}
    command: ["-token","${GRAFANA_PDC_TOKEN}","-cluster","${GRAFANA_PDC_CLUSTER}","-gcloud-hosted-grafana-id","${GRAFANA_PDC_GCP_ID}"]

  alloy:
    image: grafana/alloy:latest
    depends_on:
      - loki
    volumes:
      # - ./alloy/config/config.alloy:/etc/alloy
      - type: bind
        source: ./alloy/config/config.alloy
        target: /etc/alloy/config.alloy
        content: |
          // Snort3 JSON log scraper with GeoIP enrichment for Loki
          // This configuration reads Snort3 JSON logs, enriches them with GeoIP data,
          // and forwards them to Loki

          // Local file component to read Snort3 logs
          local.file_match "snort3_logs" {
            path_targets = [{"__path__" = "/var/log/snort/*.txt"}]
          }

          // Scrape Snort3 JSON logs from file
          loki.source.file "snort3" {
            targets    = local.file_match.snort3_logs.targets
            forward_to = [loki.process.add_geoip.receiver]
          }

          // Process logs to extract JSON and add GeoIP information
          loki.process "add_geoip" {
            // Extract JSON fields
            stage.json {
              expressions = {
                timestamp = "timestamp",
                pkt_num   = "pkt_num",
                proto     = "proto",
                pkt_gen   = "pkt_gen",
                pkt_len   = "pkt_len",
                dir       = "dir",
                src_ap    = "src_ap",
                dst_ap    = "dst_ap",
                rule      = "rule",
                action    = "action",
              }
            }

            // Extract source IP (handle both IPv4:port and IPv6 without port)
            // IPv4 format: 192.168.1.1:8080 or 192.168.1.1
            // IPv6 format: fe80::1234:5678:abcd:ef12 (no port in Snort3 output)
            stage.regex {
              expression = "^(?P<src_ip>(?:[0-9a-fA-F:]+::[0-9a-fA-F:]*|[0-9a-fA-F:]+:[0-9a-fA-F:]+:[0-9a-fA-F:]+|[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}))(?::(\\d+))?$"
              source     = "src_ap"
            }

            // Extract destination IP (handle both IPv4:port and IPv6 without port)
            stage.regex {
              expression = "^(?P<dst_ip>(?:[0-9a-fA-F:]+::[0-9a-fA-F:]*|[0-9a-fA-F:]+:[0-9a-fA-F:]+:[0-9a-fA-F:]+|[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}))(?::(\\d+))?$"
              source     = "dst_ap"
            }

            // Add GeoIP information for source IP
            stage.geoip {
              db      = "/geoip/GeoLite2-City.mmdb"
              source  = "src_ip"
              db_type = "city"
            }

            // Rename GeoIP fields to distinguish source location (as structured metadata, not labels)
            stage.structured_metadata {
              values = {
                src_country      = "geoip_country_name",
                src_country_code = "geoip_country_code",
                src_city         = "geoip_city_name",
                src_latitude     = "geoip_latitude",
                src_longitude    = "geoip_longitude",
                src_timezone     = "geoip_timezone",
                src_subdivision  = "geoip_subdivision_name",
              }
            }

            // Add GeoIP information for destination IP
            stage.geoip {
              db      = "/geoip/GeoLite2-City.mmdb"
              source  = "dst_ip"
              db_type = "city"
            }

            // Add destination GeoIP as structured metadata
            stage.structured_metadata {
              values = {
                dst_country      = "geoip_country_name",
                dst_country_code = "geoip_country_code",
                dst_city         = "geoip_city_name",
                dst_latitude     = "geoip_latitude",
                dst_longitude    = "geoip_longitude",
                dst_timezone     = "geoip_timezone",
                dst_subdivision  = "geoip_subdivision_name",
              }
            }

            // Add static labels for filtering
            stage.static_labels {
              values = {
                job      = "snort3",
                source   = "snort_ids",
              }
            }

            // Add all extracted fields as structured metadata (stored as values, not indexed)
            stage.structured_metadata {
              values = {
                timestamp = "timestamp",
                pkt_num   = "pkt_num",
                proto     = "proto",
                pkt_gen   = "pkt_gen",
                pkt_len   = "pkt_len",
                dir       = "dir",
                src_ap    = "src_ap",
                dst_ap    = "dst_ap",
                src_ip    = "src_ip",
                dst_ip    = "dst_ip",
                rule      = "rule",
                action    = "action",
              }
            }

            forward_to = [loki.write.loki_endpoint.receiver]
          }

          // Write to Loki
          loki.write "loki_endpoint" {
            endpoint {
              url = "http://loki:3100/loki/api/v1/push"
              
              // Optional: Add basic auth if needed
              // basic_auth {
              //   username = "loki"
              //   password = "password"
              // }
            }
          }
      - ./alloy/data:/var/lib/alloy/data
      - ./geoip:/geoip:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /data/coolify/proxy/logs:/traefik/logs:ro
      - /var/log/snort:/var/log/snort:ro
    command: 'run --server.http.listen-addr=0.0.0.0:12345 --storage.path=/var/lib/alloy/data /etc/alloy/config.alloy'
    labels:
      - traefik.http.middlewares.authentik@file

  loki:
    image: grafana/loki:latest
    user: "0:0"
    volumes:
      - ./loki/data:/loki
      - type: bind
        source: ./loki/config.yml
        target: /etc/loki/loki-config.yaml
        content: |
          # (default configuration)
          auth_enabled: false

          server:
            http_listen_port: 3100

          ingester:
            lifecycler:
              address: 127.0.0.1
              ring:
                kvstore:
                  store: inmemory
                replication_factor: 1
              final_sleep: 0s
            chunk_idle_period: 1h       # Any chunk not receiving new logs in this time will be flushed
            max_chunk_age: 1h           # All chunks will be flushed when they hit this age, default is 1h
            chunk_target_size: 1048576  # Loki will attempt to build chunks up to 1.5MB, flushing first if chunk_idle_period or max_chunk_age is reached first
            chunk_retain_period: 30s    # Must be greater than index read cache TTL if using an index cache (Default index read cache TTL is 5m)

          schema_config:
            configs:
              - from: 2020-10-24
                # store: boltdb-shipper
                store: tsdb
                object_store: filesystem
                schema: v13
                index:
                  prefix: index_
                  period: 24h

          storage_config:
            # boltdb_shipper:
            #   active_index_directory: /loki/boltdb-shipper-active
            #   cache_location: /loki/boltdb-shipper-cache
            #   cache_ttl: 24h         # Can be increased for faster performance over longer query periods, uses more disk space    shared_store: filesystem
            filesystem:
              directory: /loki/chunks
            # Configures storing index in an Object Store
            # (GCS/S3/Azure/Swift/COS/Filesystem) in a prometheus TSDB-like format. Required
            # fields only required when TSDB is defined in config.
            tsdb_shipper:
              # Directory where ingesters would write index files which would then be
              # uploaded by shipper to configured storage
              # CLI flag: -tsdb.shipper.active-index-directory
              active_index_directory: /loki/index

              # Cache location for restoring index files from storage for queries
              # CLI flag: -tsdb.shipper.cache-location
              cache_location: /loki/cache

              # TTL for index files restored in cache for queries
              # CLI flag: -tsdb.shipper.cache-ttl
              # [cache_ttl: <duration> | default = 24h]

              # Resync downloaded files with the storage
              # CLI flag: -tsdb.shipper.resync-interval
              # [resync_interval: <duration> | default = 5m]

              # Number of days of common index to be kept downloaded for queries. For per
              # tenant index query readiness, use limits overrides config.
              # CLI flag: -tsdb.shipper.query-ready-num-days
              # [query_ready_num_days: <int> | default = 0]

              # index_gateway_client:
                # The grpc_client block configures the gRPC client used to communicate
                # between a client and server component in Loki.
                # The CLI flags prefix for this block configuration is:
                # querier.frontend-grpc-client
                # [grpc_client_config: <grpc_client>]

                # Hostname or IP of the Index Gateway gRPC server running in simple mode.
                # Can also be prefixed with dns+, dnssrv+, or dnssrvnoa+ to resolve a DNS A
                # record with multiple IP's, a DNS SRV record with a followup A record
                # lookup, or a DNS SRV record without a followup A record lookup,
                # respectively.
                # CLI flag: -tsdb.shipper.index-gateway-client.server-address
                # [server_address: <string> | default = ""]

                # Whether requests sent to the gateway should be logged or not.
                # CLI flag: -tsdb.shipper.index-gateway-client.log-gateway-requests
                # [log_gateway_requests: <boolean> | default = false]

              # [ingestername: <string> | default = ""]

              # [mode: <string> | default = ""]

              # [ingesterdbretainperiod: <duration>]

          compactor:
            working_directory: /loki/boltdb-shipper-compactor

          limits_config:
            reject_old_samples: true
            reject_old_samples_max_age: 168h
            ingestion_burst_size_mb: 16
            ingestion_rate_mb: 16

          table_manager:
            retention_deletes_enabled: false
            retention_period: 0s

          ruler:
            storage:
              type: local
              local:
                directory: /loki/rules
            rule_path: /loki/rules-temp
            alertmanager_url: localhost
            ring:
              kvstore:
                store: inmemory
            enable_api: true
    command: -config.file=/etc/loki/loki-config.yaml
    environment:
      - TZ=$TZ

  prometheus:
    image: prom/prometheus:main
    user: "0:0"
    volumes:
      - ./prometheus/data:/prometheus
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
      - type: bind
        source: ./prometheus/config.yml
        target: /etc/prometheus/prometheus.yml
        content: |
          global:
            scrape_interval: 15s
            evaluation_interval: 15s
          rule_files:
            - 'alert.rules'
          scrape_configs:
            - job_name: 'cadvisor'
              scrape_interval: 5s
              static_configs:
                - targets:
                  - cadvisor:8080
            - job_name: 'node_exporter'
              scrape_interval: 5s
              static_configs:
                - targets:
                  - node_exporter:9100
            - job_name: 'speedtest'
              scrape_interval: 1h
              scrape_timeout: 1m
              static_configs:
                - targets:
                  - speedtest:9798

      - type: bind
        source: ./prometheus/alert.rules.yml
        target: /etc/prometheus/alert.rules.yml
        content: |
          groups:
          - name: traefik
            rules:
            - alert: service_down
              expr: up == 0
              for: 2m
              labels:
                severity: page
              annotations:
                summary: "Instance {{ $$labels.instance }} down"
                description: "{{ $$labels.instance }} of job {{ $$labels.job }} has been down for more than 2 minutes"

    command:
      - "--web.route-prefix=/"
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/usr/share/prometheus/console_libraries"
      - "--web.console.templates=/usr/share/prometheus/consoles"
      - "--web.enable-lifecycle"
    environment:
      - TZ=${TZ}

  speedtest:
    image: miguelndecarvalho/speedtest-exporter
    environment:
      - SPEEDTEST_PORT=9798
